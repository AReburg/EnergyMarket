{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules/libraries\n",
    "import warnings \n",
    "warnings.simplefilter(action='ignore')\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import time\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import geojson\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "import chardet\n",
    "from scipy import spatial\n",
    "from scipy.spatial import KDTree\n",
    "from shapely import wkt\n",
    "\n",
    "cwd = Path().resolve()\n",
    "\n",
    "# visualisation\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl \n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Engineering <a class=\"anchor\" id=\"data-engineering\"></a>\n",
    "\n",
    "https://www.entsoe.eu/data/map/\n",
    "\n",
    "https://transparency.entsog.eu/#/map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df.apply(lambda x: get_price(x['price']), axis=1)\n",
    "\n",
    "df['neighbourhood'] = df['neighbourhood'].str.replace('Landstra§e', 'Landstraße')\n",
    "df['neighbourhood'] = df['neighbourhood'].str.replace('Rudolfsheim-Fnfhaus', 'Rudolfsheim-Fünfhaus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_geo_data():\n",
    "    \"\"\" load geojson data \"\"\"\n",
    "    with open(os.path.join(Path(cwd).parent, 'data', 'geojson', 'vienna.geojson'), encoding='utf-8') as fp:\n",
    "        counties = geojson.load(fp)\n",
    "    return counties\n",
    "\n",
    "def save_figure(fig, name):\n",
    "    with open(f\"{name}.json\", \"w\") as outfile:\n",
    "        outfile.write(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def heatmap_airbnb2(title=''):\n",
    "    \"\"\" \"\"\"\n",
    "    districts = get_geo_data()\n",
    "    k = aggregate_data(df, 'neighbourhood', {'neighbourhood':['first'], 'price':['median'], 'host_is_superhost': ['first']},\\\n",
    "                       rename=['district', 'median', 'host_is_superhost'])\n",
    "    k.sort_values(by='median', ascending=True, inplace=True)\n",
    "    k['median'] = k['median'].astype('category')\n",
    "    k.sort_values(by='median', ascending = False, inplace=True)\n",
    "    fig = px.choropleth_mapbox(k, geojson=districts, locations=k['district'], featureidkey=\"properties.name\", \n",
    "                               color=k['median'],\n",
    "                               title=title,\n",
    "                               color_discrete_sequence=px.colors.qualitative.Prism, \n",
    "                               labels={'median':'price per night'},\n",
    "        mapbox_style=\"open-street-map\", zoom=10, center = {\"lat\": 48.210033, \"lon\": 16.363449}, opacity=0.60)\n",
    "    \n",
    "    fig.add_scattermapbox(\n",
    "        lat=df['latitude'].tolist(),\n",
    "        lon=df['longitude'].tolist(),\n",
    "        mode='markers',\n",
    "        showlegend=False,\n",
    "        #text=texts,\n",
    "        marker_size=5,\n",
    "        marker_color='#F3B5B6',\n",
    "        opacity= 0.5,\n",
    "        hoverinfo='skip'\n",
    "    )\n",
    "    fig.update_layout(font=dict(family=\"Helvetica\"))\n",
    "    fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.update_layout(autosize=False,width=700,height=500)\n",
    "    \n",
    "    save_figure(fig.to_json(), \"test\")\n",
    "    fig.show()\n",
    "\n",
    "    \n",
    "def heatmap_airbnb(title=''):\n",
    "    \"\"\" \"\"\"\n",
    "    districts = get_geo_data()\n",
    "    agg = df.groupby('neighbourhood').agg(nr_listings = ('id', 'count')).reset_index().sort_values('nr_listings', ascending=False)\n",
    "    agg['ratio'] = 100 * agg['nr_listings'] / agg['nr_listings'].sum()\n",
    "    agg['nr_listings'] = agg['nr_listings'].astype('category')\n",
    "    agg.sort_values(by='nr_listings', ascending = False, inplace=True)\n",
    "    fig = px.choropleth_mapbox(agg, geojson=districts, locations=agg['neighbourhood'], featureidkey=\"properties.name\",\n",
    "                               color_discrete_sequence=px.colors.qualitative.Dark24,\n",
    "                               color=agg['nr_listings'],\n",
    "                               #color=agg['ratio'],\n",
    "                               title=title,\n",
    "                               labels={'nr_listings':'Nr. of listings'},\n",
    "        mapbox_style=\"open-street-map\", zoom=10, center = {\"lat\": 48.210033, \"lon\": 16.363449}, opacity=0.40)\n",
    "    \n",
    "    fig.add_scattermapbox(\n",
    "        lat=df['latitude'].tolist(),\n",
    "        lon=df['longitude'].tolist(),\n",
    "        mode='markers',\n",
    "        #text=texts,\n",
    "        marker_size=2,\n",
    "        marker_color='#F3F5F6',\n",
    "        opacity= 0.9,\n",
    "        showlegend=True,\n",
    "        hoverinfo='skip' #hoverinfo='none'\n",
    "    )\n",
    "    fig.update_layout(font=dict(family=\"Helvetica\"))\n",
    "    fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.update_layout(autosize=False,width=700,height=500)\n",
    "    \n",
    "    save_figure(fig.to_json(), \"test2\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def bar_airbnb(df):\n",
    "    \"\"\"generates the bar chart of the category distribution from the \"direct\" genre \"\"\"\n",
    "    agg = df.groupby('neighbourhood').agg(nr_listings = ('id', 'count')).reset_index().sort_values('nr_listings', ascending=False)\n",
    "    agg['ratio'] = 100 * agg['nr_listings'] / agg['nr_listings'].sum()\n",
    "    fig = px.bar(x=agg['neighbourhood'].tolist(), y=agg['ratio'])\n",
    "    save_figure(fig.to_json(), \"barchart2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_reviews_over_time(data_reviews):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "    go.Scatter(x=data_reviews['date'], y=data_reviews['num_reviews'], showlegend=False, line=dict(color='#2c6e81', width=1)))\n",
    "    fig.update_layout( font=dict(family=\"Open Sans\"), legend_font_size=14),\n",
    "    fig.add_trace(go.Scatter(x=data_reviews['date'], y=data_reviews['num_reviews'].rolling(20).mean(), \n",
    "                             name =\"SMA 20\", line=dict(color='orange', width=2), showlegend=True))\n",
    "    # fig.update_layout(xaxis=dict(tickformat=\"%b\"))\n",
    "    fig.update_layout(yaxis_title=\"Nr. of reviews\")\n",
    "    fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig.update_layout(legend=dict(yanchor='top',y=.95,xanchor='left',x=0.01))\n",
    "    fig.update_layout(autosize=False,width=700,height=350)\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()\n",
    "\n",
    "df_reviews = df_rev.copy()\n",
    "# Group by on date and count how many reviews were made on that day\n",
    "data_reviews = df_reviews.groupby('date').count()['listing_id'].reset_index()\n",
    "# Reset the column names\n",
    "data_reviews.columns = ['date', 'num_reviews']\n",
    "# Cast the datatype of the date column so that we can use plot_date.\n",
    "data_reviews['date'] = pd.to_datetime(data_reviews['date'])\n",
    "data_reviews.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn OpenStreetMap Location Data into ML Features <a class=\"anchor\" id=\"osm-features\"></a>\n",
    "#### How to pull shops, restaurants, public transport modes and other local amenities into your ML models\n",
    "With this information it might be possible to find a reasonable model with ammeniteis which affect what a host will charge for an airbnb.\n",
    "\n",
    "##### Define Area of Interest\n",
    "In this case the area of Vienna is imported from a geojson file into a geopandas dataframe. This datframe needs to be converted to a polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_geojson = gpd.read_file(os.path.join(Path(cwd).parent, 'data', 'geojson', 'vienna.geojson'))\n",
    "boundary_geojson.drop(columns=['cartodb_id', 'created_at', 'updated_at'], inplace=True)\n",
    "region = boundary_geojson.geometry.unary_union\n",
    "\n",
    "def get_local_crs(y,x):  \n",
    "    x = ox.utils_geo.bbox_from_point((y, x), dist = 500, project_utm = True, return_crs = True)\n",
    "    return x[-1]\n",
    "  \n",
    "# Set longitude and latitude of Vienna\n",
    "lon_latitude = 48.210033\n",
    "lon_longitude = 16.363449\n",
    "\n",
    "local_utm_crs = get_local_crs(lon_latitude, lon_longitude)\n",
    "# print(f\"boundary data type: {type(boundary_geojson)}, region data type: {type(region)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pull list of all amenities from OSM wiki page for reference\n",
    "To get all the OSM queries especially for amenities, a list with all the keys is displayed from the [Openstreetmap wiki](https://wiki.openstreetmap.org/wiki/Key:amenity). This OSM data is accessible through the osmnx python module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_amenities():\n",
    "    \"\"\" get all amenitiy keys from OSM wiki \"\"\"\n",
    "    try:\n",
    "        amenities = pd.read_html('https://wiki.openstreetmap.org/wiki/Key:amenity', skiprows = 0, header=0, attrs = {'class': 'wikitable sortable toptextcells zebra jquery-tablesorter'})[0]\n",
    "       # amenities.drop(columns=['Element', 'Carto rendering','Photo', 'Unnamed: 6'], inplace=True, axis=1)\n",
    "        amenities.drop(index=0, inplace=True)\n",
    "        return amenities\n",
    "    except Excepion as e:\n",
    "        print(\"Amenities could not be found\")\n",
    "\n",
    "\n",
    "amenities = get_all_amenities()\n",
    "print(f\"First ten amenity keys: {', '.join(amenities['Value'].tolist()[0:10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_osm_data(region, data):\n",
    "    df = ox.geometries.geometries_from_polygon(region, tags=data[0])\n",
    "    df.to_csv(os.path.join(Path(cwd).parent, 'data', 'osm', \n",
    "                           f'{list(data[0].values())[0]}.csv'), columns=['geometry'])\n",
    "    return df\n",
    "\n",
    "t0 = time.time()\n",
    "cafe = get_osm_data(region, [{'amenity':'cafe'}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Query the OSM location data with osmnx\n",
    "\n",
    "```python\n",
    "def get_osm_data(region, data):\n",
    "    df = ox.geometries.geometries_from_polygon(region, tags=data[0])\n",
    "    df.to_csv(os.path.join(Path(cwd).parent, 'data', 'osm', \n",
    "                           f'{list(data[0].values())[0]}.csv'), columns=['geometry'])\n",
    "    return df\n",
    "\n",
    "t0 = time.time()\n",
    "cafe = get_osm_data(region, [{'amenity':'cafe'}])\n",
    "restaurant = get_osm_data(region, [{'amenity':'restaurant'}])\n",
    "attraction = get_osm_data(region, [{'tourism':'attraction'}])\n",
    "station = get_osm_data(region, [{'station':'subway'}])\n",
    "bar = get_osm_data(region, [{'amenity':'bar'}])\n",
    "biergarten = get_osm_data(region, [{'amenity':'biergarten'}])\n",
    "fast_food = get_osm_data(region, [{'amenity':'fast_food'}])\n",
    "pub = get_osm_data(region, [{'amenity':'pub'}])\n",
    "nightclub = get_osm_data(region, [{'amenity':'nightclub'}])\n",
    "theatre = get_osm_data(region, [{'amenity':'theatre'}])\n",
    "university = get_osm_data(region, [{'amenity':'university'}])\n",
    "attraction = get_osm_data(region, [{'tourism':'attraction'}])\n",
    "shop = get_osm_data(region, [{'shop':'supermarket'}])\n",
    "\n",
    "roads = ox.graph.graph_from_polygon(region)\n",
    "forest = ox.geometries.geometries_from_polygon(region, tags = {'landuse': 'forest'})\n",
    "rivers = ox.geometries.geometries_from_polygon(region, tags = {'waterway': 'river'})\n",
    "#building: True means that every type of buildings will be downloaded\n",
    "#buildings = ox.geometries.geometries_from_polygon(region, tags = {'building': True})\n",
    "#kindergarten = ox.geometries.geometries_from_polygon(region, tags = {'amenity':'kindergarten'})\n",
    "#secondary_roads = ox.geometries.geometries_from_polygon(region, tags = {'highway': 'secondary'})\n",
    "print (f\"Completed in {round(time.time() - t0)} s\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv_to_gpd(name):\n",
    "    \"\"\" import the csv file a gepandas dataframe \"\"\"\n",
    "    df = pd.read_csv(os.path.join(Path(cwd).parent, 'data', 'osm', f'{name}.csv'), sep=\",\")\n",
    "    df['geometry'] = df['geometry'].apply(wkt.loads)\n",
    "    gdf = gpd.GeoDataFrame(df, crs='epsg:4326')\n",
    "    return gdf\n",
    "\n",
    "restaurant = import_csv_to_gpd('restaurant')\n",
    "cafe = import_csv_to_gpd('cafe')\n",
    "attraction = import_csv_to_gpd('attraction')\n",
    "subway = import_csv_to_gpd('subway')\n",
    "bar = import_csv_to_gpd('bar')\n",
    "biergarten = import_csv_to_gpd('biergarten')\n",
    "fast_food = import_csv_to_gpd('fast_food')\n",
    "pub = import_csv_to_gpd('pub')\n",
    "nightclub = import_csv_to_gpd('nightclub')\n",
    "theatre = import_csv_to_gpd('theatre')\n",
    "university= import_csv_to_gpd('university')\n",
    "shop = import_csv_to_gpd('supermarket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization of OSM Features:\n",
    "\n",
    "```python\n",
    "ax = boundary_geojson.plot(facecolor = '#494D4D', figsize=(85,85))\n",
    "ax.set_facecolor('#2C2E2E')\n",
    "#buildings['geometry'].plot(facecolor = '#C61313', edgecolor = '#C61313', linewidth = 3, markersize = 1, ax = ax)\n",
    "forest.plot(facecolor = '#494D4D', edgecolor = '#ADC3B8', linewidth = 2, linestyle = ':', hatch ='x', ax=ax)\n",
    "rivers.plot(edgecolor='#67A0C3', linewidth=6, linestyle='-', ax=ax)\n",
    "ox.plot_graph(roads, edge_color='white', node_color='white', edge_linewidth=2, node_size=2, ax=ax)\n",
    "ax.grid('on', which='major', axis='x', color = '#99A2A2')\n",
    "ax.grid('on', which='major', axis='y', color = '#99A2A2')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turning the Data Into Features\n",
    "What we currently have is a dataframe of all the restaurants in London. For a machine learning model, what we need is the number of restaurants within a 10-minute walk each Airbnb property. Quite a bit of manipulation is required to get to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geo dataframe has a column defining the geometry (e.g. POINT, POLYGON, Mult-Polygon). Restaurant locations for instance come as a point object and the latitude and longitude coordination need to be extracted.\n",
    "\n",
    "##### Convert Polygons into Points\n",
    "Most properties are returned as a single point coordinate. However, some are returned in a different shape e.g POLYGON, MulitPOLYGON or LINESTRING (e.g. on larger properties). In order to work with polygons, only their center point is used for subsequent feature extraction and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_long(point):\n",
    "    \"\"\" get latitude and longitude coordinate from POINT geometry \"\"\"\n",
    "    try:\n",
    "        return pd.Series([point.x, point.y])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def geo_coordinates(df):\n",
    "    \"\"\" import from csv in geopandas dataframe\n",
    "    source: https://stackoverflow.com/questions/61122875/geopandas-how-to-read-a-csv-and-convert-to-a-geopandas-dataframe-with-polygons\n",
    "    \"\"\"\n",
    "    df['geometry'] = df['geometry'].apply(lambda x: x.centroid if type(x) == Polygon else (x.centroid if type(x) == MultiPolygon else x))\n",
    "    df[['long', 'lat']] = df.apply(lambda x: get_lat_long(x['geometry']), axis=1)\n",
    "    df = df[df['geometry'].apply(lambda x : x.type=='Point' )]\n",
    "    df = df.to_crs(local_utm_crs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant = geo_coordinates(restaurant)\n",
    "cafe = geo_coordinates(cafe)\n",
    "bar = geo_coordinates(bar)\n",
    "subway = geo_coordinates(subway)\n",
    "biergarten = geo_coordinates(biergarten)\n",
    "fast_food = geo_coordinates(fast_food)\n",
    "pub = geo_coordinates(pub)\n",
    "nightclub = geo_coordinates(nightclub)\n",
    "theatre = geo_coordinates(theatre)\n",
    "university = geo_coordinates(university)\n",
    "attraction = geo_coordinates(attraction)\n",
    "shop = geo_coordinates(shop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate Distances with a KD Tree\n",
    "Iterate through each AirBnb property and work out how many respective Openstreetmap features there are within a radius of 1 km. This is done using a KD Tree which is an efficient way of searching through our 12,000 AirBnbs rooms and thousend of features figuring out which ones are close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree(df):\n",
    "    try:\n",
    "        # turn long/lats into a list\n",
    "        coords = list(zip(df.geometry.apply(lambda x: x.y).values,df.geometry.apply(lambda x: x.x).values))\n",
    "        # create a KDTree\n",
    "        tree = spatial.KDTree(coords)\n",
    "        return tree\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step a function is created which is performed on each of the Airbnb properties. The function will query the tree and find the 500 closest restaurants along with calculating their distances from the Airbnb property. We use a figure of 500 in the hope that no property has more than 500 restaurants close to it.\n",
    "With this approach it can be determined how many restaurants, bars, shops, subway stations, tourist hotspots, public parks etc. there are within a 10-minute walk of each Airbnb property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_points_closeby(tree, lat_lon, k = 500, max_distance = 500 ):\n",
    "    results = tree.query((lat_lon), k = k, distance_upper_bound= max_distance)\n",
    "    zipped_results = list(zip(results[0], results[1]))\n",
    "    zipped_results = [i for i in zipped_results if i[0] != np.inf]\n",
    "    return len(zipped_results)\n",
    "\n",
    "t0 = time.time()\n",
    "air_gdf = df.copy()\n",
    "\n",
    "parameters = [restaurant, cafe , bar, subway, biergarten, fast_food, pub, nightclub,theatre,university,attraction]\n",
    "names = ['restaurant', 'cafe', 'bar', 'subway', 'biergarten', 'fast_food', 'pub', 'nightclub','theatre','university','attraction']\n",
    "\n",
    "air_gdf = gpd.GeoDataFrame(air_gdf, geometry = gpd.points_from_xy(air_gdf.longitude, air_gdf.latitude), crs = 4326)\n",
    "air_gdf = air_gdf.to_crs(local_utm_crs)\n",
    "\n",
    "for name, i in zip(names, parameters):\n",
    "    tree = get_tree(i)\n",
    "    air_gdf[name] = air_gdf.apply(lambda row: find_points_closeby(tree, (row.geometry.y, row.geometry.x)) , axis = 1)\n",
    "\n",
    "print (f\"Completed in {round(time.time() - t0)} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.heatmap(air_gdf.corr(), ax=ax, annot=True, fmt=\".2f\");\n",
    "# fig.savefig(\"correlation-matrix.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_amenities(fig, df, showlegend=True, name='', marker_color='rgb(135, 60, 200)', marker_size=5, marker='circle'):\n",
    "    fig.add_scattermapbox(\n",
    "        lat=df.lat.tolist(),\n",
    "        lon=df.long.tolist(),\n",
    "        #marker_symbol=marker,\n",
    "        mode='markers', #'markers+text'\n",
    "        #text=texts,\n",
    "        #marker = marker,\n",
    "        marker_size=marker_size,\n",
    "        marker_color=marker_color,\n",
    "        opacity= 0.8,\n",
    "        showlegend=showlegend,\n",
    "                #hover_data=['amenity'],\n",
    "       # hoverinfo='restaurant'\n",
    "      #  label={'trace 1':'test'},\n",
    "        name=name)\n",
    "\n",
    "def heatmap(df, title=''):\n",
    "    \"\"\" selector specifies the geographic resolution \n",
    "    source: https://stackoverflow.com/questions/67680264/combining-mapbox-choropleth-with-additional-layers-and-markers-in-python-try-to\n",
    "    additional markers : https://plotly.github.io/plotly.py-docs/generated/plotly.express.scatter_mapbox.html\n",
    "    https://plotly.com/python/scatter-plots-on-maps/\n",
    "    \"\"\"\n",
    "    feat_key = ''\n",
    "    locations = ''\n",
    "    hover_data = ''\n",
    "    j = get_geo_data()\n",
    "    fig = px.choropleth_mapbox(df, geojson=j, locations=test['name'], featureidkey=\"properties.name\", color=test['value'],\n",
    "                               title=title,\n",
    "        mapbox_style=\"open-street-map\", zoom=10, center = {\"lat\": 48.210033, \"lon\": 16.363449}, opacity=0.15)\n",
    "    \n",
    "    lons = [item['geometry']['coordinates'][0][0][0][1] for item in j['features']]\n",
    "    lats = [item['geometry']['coordinates'][0][0][0][0] for item in j['features']]\n",
    "    texts = [item['properties']['name'] for item in j['features']]\n",
    "\n",
    "    marker = itertools.cycle(('circle')) \n",
    "    add_amenities(fig, fast_food, name='Restaurants', marker_color='rgb(240, 240, 200)', marker_size=12, marker=next(marker))\n",
    "    add_amenities(fig, pub, name='Pubs', marker_color='rgb(255, 87, 200)', marker_size=1, marker=next(marker)) \n",
    "   \n",
    "    add_amenities(fig, bar, name='Bar', marker_color='rgb(135, 60, 200)', marker_size=5, marker=next(marker))\n",
    "    add_amenities(fig, cafe, name='Cafe', marker_color='rgb(135, 60, 200)', marker_size=7, marker=next(marker))    \n",
    "    add_amenities(fig, fast_food, name='Fast food', marker_color='rgb(135, 60, 200)', marker_size=8, marker=next(marker)) \n",
    "    add_amenities(fig, subway, name='Subway', marker_color='rgb(135, 60, 200)', marker_size=6, marker=next(marker)) \n",
    "    add_amenities(fig, biergarten, name='Biergarten', marker_color='rgb(135, 60, 200)', marker_size=5, marker=next(marker)) \n",
    "    add_amenities(fig, attraction, name='Attraction', marker_color='rgb(135, 60, 200)', marker_size=5, marker=next(marker)) \n",
    "    add_amenities(fig, university, name='University', marker_color='rgb(40, 120, 43)', marker_size=2, marker=next(marker)) \n",
    "    add_amenities(fig, nightclub, name='Nightclub', marker_color='rgb(45, 67, 12)', marker_size=5, marker=next(marker))\n",
    "\n",
    "    fig.update_coloraxes(showscale=False)\n",
    "    fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.update_layout(autosize=False,width=700,height=500)\n",
    "    fig.show()\n",
    "\n",
    "test = boundary_geojson.copy()\n",
    "\n",
    "test.reset_index(inplace=True)\n",
    "test['value'] =  test['index']*1.2\n",
    "heatmap(boundary_geojson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, make_scorer\n",
    "\n",
    "def display_results(cv, y_test, y_pred):\n",
    "    \"\"\" check how well the model performs. \"\"\"\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"\\nBest Parameters:\", cv.best_params_)\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, category_names):\n",
    "    \"\"\" evaluate how well the given model performs with test data set \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    class_report = classification_report(y_test, y_pred, target_names=category_names)\n",
    "    print(class_report)\n",
    "\n",
    "def save_model(model, model_filepath):\n",
    "    \"\"\" save model as a .pkl file under a give file path \"\"\"\n",
    "    with open(model_filepath, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "\n",
    "# Separate the target variable and rest of the variables\n",
    "X, y = air_gdf[['restaurant','cafe', 'bar', 'subway','biergarten','fast_food','pub','nightclub',\n",
    "                'theatre','university']], air_gdf['price']\n",
    "\n",
    "# Convert the dataset into an optimized data structure called Dmatrix that XGBoost supports and gives it acclaimed performance and efficiency gains. You will use this later in the tutorial.\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123)\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "save_model(model, os.path.join(Path(cwd).parent, 'model', 'xboost.pkl'))\n",
    "\n",
    "# feature importance\n",
    "print(model.feature_importances_)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Compute the rmse by invoking the mean_sqaured_error function from sklearn's metrics module.\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "params = {}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "print((cv_results[\"test-rmse-mean\"]).tail(1))\n",
    "\n",
    "xgb.plot_importance(model)\n",
    "plt.rcParams['figure.figsize'] = [6, 6]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example to predict benchmark price\n",
    "d = {'restaurant': 3, 'cafe': 100, 'bar':5, 'subway':3, 'biergarten':1, 'fast_food':15, 'pub':3,\n",
    "    'nightclub':1,'theatre':0,'university':0}\n",
    "X_pred = pd.DataFrame(data=d, index=[0])\n",
    "preds = model.predict(X_pred)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "In my final XGBoost model, as you can see below, these OSM features (highlighted in red) ended up being some of the most important drivers of price in London."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Convert notebook to html\n",
    "```python\n",
    "!jupyter nbconvert --to html Airbnb-Analysis.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download notebook to html\n",
    "!jupyter nbconvert --to html Airbnb-Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(Path(cwd).parent, 'data', f'airbnb_dataframe.csv'), columns=['id', 'price', 'latitude', 'longitude', 'neighbourhood'], sep=',', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
